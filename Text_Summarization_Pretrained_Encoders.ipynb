{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Summarization_Pretrained_Encoders.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUU3boagn-ug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57197d08-c2fb-4b16-8c35-17f195614b3b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL671BsmUeTP"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spuRrrv-u2mi",
        "outputId": "10b7223d-22d6-4908-8570-d5724f0ab100"
      },
      "source": [
        "pip install pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.17.48)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.0.44)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.1.95)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.48 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (1.20.48)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.3.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.48->boto3->pytorch_transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u70w1rnopI_",
        "outputId": "c0f9ecb4-3f1d-4fb4-8b5b-cd39c8cb5967"
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (54.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psFecNaUrjjV",
        "outputId": "c013e5df-d9a1-4a83-9088-5be2885d66b9"
      },
      "source": [
        "pip install torch==1.1.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.1.0) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-ReRuf8pPYq",
        "outputId": "8b6698c0-0bf4-4a25-82e4-348e225d0fff"
      },
      "source": [
        "pip install pyrouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyrouge in /usr/local/lib/python3.7/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln64XF1gz_eL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a32d925-4d9d-4588-e7fb-9bdb122fe33b"
      },
      "source": [
        "\"\"\"\n",
        "import torch \n",
        "print(torch.__version__)\n",
        "\n",
        "print(torch.cuda.current_device())\n",
        "print(torch.cuda.device(0))\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.current_device())\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1.0\n",
            "0\n",
            "<torch.cuda.device object at 0x7f470823a210>\n",
            "1\n",
            "Tesla T4\n",
            "True\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKnOaQcq5YiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b2b45a-fb14-4591-eb7e-85daab05148b"
      },
      "source": [
        "#torch.randn(5).cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.6523,  0.3888, -0.8512, -0.1287, -0.4638], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfOB5nKmUZbp"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HUI04YgKosc",
        "outputId": "9f7d89c3-f9d9-44fb-e7f4-4e90092ea10f"
      },
      "source": [
        "# !python /content/drive/MyDrive/nlpyang/PreSumm-master/src/train.py -task ext -mode test_text -bert_data_path /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm -ext_dropout 0.1 -model_path /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH -lr 2e-3 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file /content/drive/MyDrive/nlpyang/PreSumm-master/logs/ext_bert_cnndm  -use_interval true -warmup_steps 10000 -max_pos 512 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-04-03 19:17:24,269 INFO] Device ID 0\n",
            "[2021-04-03 19:17:24,537 INFO] Device cuda\n",
            "[2021-04-03 19:17:25,125 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpn21x8pw4\n",
            "100% 433/433 [00:00<00:00, 420498.64B/s]\n",
            "[2021-04-03 19:17:25,406 INFO] copying /tmp/tmpn21x8pw4 to cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "[2021-04-03 19:17:25,407 INFO] creating metadata file for ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "[2021-04-03 19:17:25,407 INFO] removing temp file /tmp/tmpn21x8pw4\n",
            "[2021-04-03 19:17:25,407 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "[2021-04-03 19:17:25,408 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[2021-04-03 19:17:25,686 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpeiavu42a\n",
            "100% 440473133/440473133 [00:12<00:00, 36488581.60B/s]\n",
            "[2021-04-03 19:17:38,108 INFO] copying /tmp/tmpeiavu42a to cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "[2021-04-03 19:17:39,479 INFO] creating metadata file for ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "[2021-04-03 19:17:39,480 INFO] removing temp file /tmp/tmpeiavu42a\n",
            "[2021-04-03 19:17:39,522 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "[2021-04-03 19:17:45,095 INFO] ExtSummarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ext_layer): ExtTransformerEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax()\n",
            "          (dropout): Dropout(p=0.1)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1)\n",
            "          (dropout_2): Dropout(p=0.1)\n",
            "        )\n",
            "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax()\n",
            "          (dropout): Dropout(p=0.1)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1)\n",
            "          (dropout_2): Dropout(p=0.1)\n",
            "        )\n",
            "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1)\n",
            "    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2021-04-03 19:17:45,181 INFO] * number of parameters: 120512513\n",
            "[2021-04-03 19:17:45,181 INFO] Start training...\n",
            "[2021-04-03 19:17:46,603 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.123.bert.pt, number of examples: 2001\n",
            "[2021-04-03 19:18:43,556 INFO] Step 50/50000; xent: 9.92; lr: 0.0000001;  18 docs/s;     57 sec\n",
            "[2021-04-03 19:19:47,270 INFO] Step 100/50000; xent: 6.85; lr: 0.0000002;  17 docs/s;    121 sec\n",
            "[2021-04-03 19:20:52,238 INFO] Step 150/50000; xent: 4.44; lr: 0.0000003;  16 docs/s;    186 sec\n",
            "[2021-04-03 19:21:46,533 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.91.bert.pt, number of examples: 1998\n",
            "[2021-04-03 19:21:58,324 INFO] Step 200/50000; xent: 3.65; lr: 0.0000004;  15 docs/s;    252 sec\n",
            "[2021-04-03 19:23:03,328 INFO] Step 250/50000; xent: 3.58; lr: 0.0000005;  16 docs/s;    317 sec\n",
            "[2021-04-03 19:24:08,850 INFO] Step 300/50000; xent: 3.45; lr: 0.0000006;  16 docs/s;    382 sec\n",
            "[2021-04-03 19:25:14,071 INFO] Step 350/50000; xent: 3.39; lr: 0.0000007;  17 docs/s;    447 sec\n",
            "[2021-04-03 19:25:55,399 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.39.bert.pt, number of examples: 2000\n",
            "[2021-04-03 19:26:20,074 INFO] Step 400/50000; xent: 3.44; lr: 0.0000008;  16 docs/s;    513 sec\n",
            "[2021-04-03 19:27:25,538 INFO] Step 450/50000; xent: 3.39; lr: 0.0000009;  16 docs/s;    579 sec\n",
            "[2021-04-03 19:28:31,022 INFO] Step 500/50000; xent: 3.28; lr: 0.0000010;  17 docs/s;    644 sec\n",
            "[2021-04-03 19:29:36,213 INFO] Step 550/50000; xent: 3.25; lr: 0.0000011;  16 docs/s;    710 sec\n",
            "[2021-04-03 19:30:04,705 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.6.bert.pt, number of examples: 2001\n",
            "[2021-04-03 19:30:42,800 INFO] Step 600/50000; xent: 3.39; lr: 0.0000012;  15 docs/s;    776 sec\n",
            "[2021-04-03 19:31:48,382 INFO] Step 650/50000; xent: 3.33; lr: 0.0000013;  16 docs/s;    842 sec\n",
            "[2021-04-03 19:32:54,018 INFO] Step 700/50000; xent: 3.31; lr: 0.0000014;  16 docs/s;    907 sec\n",
            "[2021-04-03 19:33:58,928 INFO] Step 750/50000; xent: 3.15; lr: 0.0000015;  16 docs/s;    972 sec\n",
            "[2021-04-03 19:34:16,631 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.81.bert.pt, number of examples: 2000\n",
            "[2021-04-03 19:35:04,986 INFO] Step 800/50000; xent: 3.14; lr: 0.0000016;  16 docs/s;   1038 sec\n",
            "[2021-04-03 19:36:10,318 INFO] Step 850/50000; xent: 3.24; lr: 0.0000017;  16 docs/s;   1104 sec\n",
            "[2021-04-03 19:37:15,845 INFO] Step 900/50000; xent: 3.21; lr: 0.0000018;  16 docs/s;   1169 sec\n",
            "[2021-04-03 19:38:21,248 INFO] Step 950/50000; xent: 3.22; lr: 0.0000019;  16 docs/s;   1235 sec\n",
            "[2021-04-03 19:38:24,755 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.98.bert.pt, number of examples: 2000\n",
            "[2021-04-03 19:39:27,578 INFO] Step 1000/50000; xent: 3.18; lr: 0.0000020;  16 docs/s;   1301 sec\n",
            "[2021-04-03 19:39:27,593 INFO] Saving checkpoint /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_1000.pt\n",
            "[2021-04-03 19:40:32,849 INFO] Step 1050/50000; xent: 3.25; lr: 0.0000021;  16 docs/s;   1366 sec\n",
            "[2021-04-03 19:41:38,017 INFO] Step 1100/50000; xent: 3.26; lr: 0.0000022;  17 docs/s;   1431 sec\n",
            "[2021-04-03 19:42:34,925 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.93.bert.pt, number of examples: 1997\n",
            "[2021-04-03 19:42:44,026 INFO] Step 1150/50000; xent: 3.15; lr: 0.0000023;  16 docs/s;   1497 sec\n",
            "[2021-04-03 19:43:49,419 INFO] Step 1200/50000; xent: 3.21; lr: 0.0000024;  16 docs/s;   1563 sec\n",
            "[2021-04-03 19:44:54,818 INFO] Step 1250/50000; xent: 3.08; lr: 0.0000025;  16 docs/s;   1628 sec\n",
            "[2021-04-03 19:45:59,968 INFO] Step 1300/50000; xent: 3.18; lr: 0.0000026;  16 docs/s;   1693 sec\n",
            "[2021-04-03 19:46:45,058 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.63.bert.pt, number of examples: 2001\n",
            "[2021-04-03 19:47:05,951 INFO] Step 1350/50000; xent: 3.19; lr: 0.0000027;  16 docs/s;   1759 sec\n",
            "[2021-04-03 19:48:11,327 INFO] Step 1400/50000; xent: 3.19; lr: 0.0000028;  16 docs/s;   1825 sec\n",
            "[2021-04-03 19:49:17,202 INFO] Step 1450/50000; xent: 3.15; lr: 0.0000029;  16 docs/s;   1891 sec\n",
            "[2021-04-03 19:50:22,262 INFO] Step 1500/50000; xent: 3.14; lr: 0.0000030;  16 docs/s;   1956 sec\n",
            "[2021-04-03 19:50:53,543 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.15.bert.pt, number of examples: 1999\n",
            "[2021-04-03 19:51:28,960 INFO] Step 1550/50000; xent: 3.15; lr: 0.0000031;  16 docs/s;   2022 sec\n",
            "[2021-04-03 19:52:34,389 INFO] Step 1600/50000; xent: 3.12; lr: 0.0000032;  17 docs/s;   2088 sec\n",
            "[2021-04-03 19:53:39,359 INFO] Step 1650/50000; xent: 3.12; lr: 0.0000033;  16 docs/s;   2153 sec\n",
            "[2021-04-03 19:54:44,627 INFO] Step 1700/50000; xent: 3.18; lr: 0.0000034;  16 docs/s;   2218 sec\n",
            "[2021-04-03 19:55:02,706 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.64.bert.pt, number of examples: 2001\n",
            "[2021-04-03 19:55:51,221 INFO] Step 1750/50000; xent: 3.11; lr: 0.0000035;  15 docs/s;   2285 sec\n",
            "[2021-04-03 19:56:56,597 INFO] Step 1800/50000; xent: 3.12; lr: 0.0000036;  16 docs/s;   2350 sec\n",
            "[2021-04-03 19:58:01,912 INFO] Step 1850/50000; xent: 3.11; lr: 0.0000037;  17 docs/s;   2415 sec\n",
            "[2021-04-03 19:59:06,790 INFO] Step 1900/50000; xent: 3.18; lr: 0.0000038;  16 docs/s;   2480 sec\n",
            "[2021-04-03 19:59:11,864 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.28.bert.pt, number of examples: 2000\n",
            "[2021-04-03 20:00:13,707 INFO] Step 1950/50000; xent: 3.08; lr: 0.0000039;  16 docs/s;   2547 sec\n",
            "[2021-04-03 20:01:19,518 INFO] Step 2000/50000; xent: 3.22; lr: 0.0000040;  16 docs/s;   2613 sec\n",
            "[2021-04-03 20:01:19,533 INFO] Saving checkpoint /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_2000.pt\n",
            "[2021-04-03 20:02:24,275 INFO] Step 2050/50000; xent: 3.10; lr: 0.0000041;  16 docs/s;   2678 sec\n",
            "[2021-04-03 20:03:22,743 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.32.bert.pt, number of examples: 1998\n",
            "[2021-04-03 20:03:30,561 INFO] Step 2100/50000; xent: 3.18; lr: 0.0000042;  16 docs/s;   2744 sec\n",
            "[2021-04-03 20:04:35,807 INFO] Step 2150/50000; xent: 3.14; lr: 0.0000043;  16 docs/s;   2809 sec\n",
            "[2021-04-03 20:05:40,919 INFO] Step 2200/50000; xent: 3.21; lr: 0.0000044;  16 docs/s;   2874 sec\n",
            "[2021-04-03 20:06:46,790 INFO] Step 2250/50000; xent: 3.10; lr: 0.0000045;  16 docs/s;   2940 sec\n",
            "[2021-04-03 20:07:32,568 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.111.bert.pt, number of examples: 2000\n",
            "[2021-04-03 20:07:53,291 INFO] Step 2300/50000; xent: 3.15; lr: 0.0000046;  16 docs/s;   3007 sec\n",
            "[2021-04-03 20:08:59,098 INFO] Step 2350/50000; xent: 3.15; lr: 0.0000047;  16 docs/s;   3072 sec\n",
            "[2021-04-03 20:10:04,400 INFO] Step 2400/50000; xent: 3.05; lr: 0.0000048;  16 docs/s;   3138 sec\n",
            "[2021-04-03 20:11:09,656 INFO] Step 2450/50000; xent: 3.10; lr: 0.0000049;  16 docs/s;   3203 sec\n",
            "[2021-04-03 20:11:41,692 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.49.bert.pt, number of examples: 2001\n",
            "[2021-04-03 20:12:15,674 INFO] Step 2500/50000; xent: 3.10; lr: 0.0000050;  16 docs/s;   3269 sec\n",
            "[2021-04-03 20:13:21,298 INFO] Step 2550/50000; xent: 3.15; lr: 0.0000051;  16 docs/s;   3335 sec\n",
            "[2021-04-03 20:14:26,689 INFO] Step 2600/50000; xent: 3.10; lr: 0.0000052;  16 docs/s;   3400 sec\n",
            "[2021-04-03 20:15:32,097 INFO] Step 2650/50000; xent: 3.17; lr: 0.0000053;  16 docs/s;   3465 sec\n",
            "[2021-04-03 20:15:53,366 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.59.bert.pt, number of examples: 2000\n",
            "[2021-04-03 20:16:39,409 INFO] Step 2700/50000; xent: 3.06; lr: 0.0000054;  16 docs/s;   3533 sec\n",
            "[2021-04-03 20:17:44,560 INFO] Step 2750/50000; xent: 3.18; lr: 0.0000055;  16 docs/s;   3598 sec\n",
            "[2021-04-03 20:18:50,104 INFO] Step 2800/50000; xent: 2.99; lr: 0.0000056;  17 docs/s;   3664 sec\n",
            "[2021-04-03 20:19:55,578 INFO] Step 2850/50000; xent: 3.04; lr: 0.0000057;  16 docs/s;   3729 sec\n",
            "[2021-04-03 20:20:03,291 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.84.bert.pt, number of examples: 2000\n",
            "[2021-04-03 20:21:02,398 INFO] Step 2900/50000; xent: 3.08; lr: 0.0000058;  16 docs/s;   3796 sec\n",
            "[2021-04-03 20:22:08,041 INFO] Step 2950/50000; xent: 3.02; lr: 0.0000059;  16 docs/s;   3861 sec\n",
            "[2021-04-03 20:23:13,206 INFO] Step 3000/50000; xent: 3.11; lr: 0.0000060;  16 docs/s;   3927 sec\n",
            "[2021-04-03 20:23:13,221 INFO] Saving checkpoint /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_3000.pt\n",
            "[2021-04-03 20:24:13,080 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.137.bert.pt, number of examples: 2000\n",
            "[2021-04-03 20:24:19,669 INFO] Step 3050/50000; xent: 3.09; lr: 0.0000061;  16 docs/s;   3993 sec\n",
            "[2021-04-03 20:25:25,388 INFO] Step 3100/50000; xent: 3.02; lr: 0.0000062;  16 docs/s;   4059 sec\n",
            "[2021-04-03 20:26:30,323 INFO] Step 3150/50000; xent: 3.08; lr: 0.0000063;  16 docs/s;   4124 sec\n",
            "[2021-04-03 20:27:36,191 INFO] Step 3200/50000; xent: 3.11; lr: 0.0000064;  16 docs/s;   4190 sec\n",
            "[2021-04-03 20:28:23,078 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.13.bert.pt, number of examples: 2001\n",
            "[2021-04-03 20:28:42,848 INFO] Step 3250/50000; xent: 3.06; lr: 0.0000065;  16 docs/s;   4256 sec\n",
            "[2021-04-03 20:29:48,461 INFO] Step 3300/50000; xent: 3.10; lr: 0.0000066;  16 docs/s;   4322 sec\n",
            "[2021-04-03 20:30:53,644 INFO] Step 3350/50000; xent: 2.97; lr: 0.0000067;  16 docs/s;   4387 sec\n",
            "[2021-04-03 20:31:59,213 INFO] Step 3400/50000; xent: 3.01; lr: 0.0000068;  16 docs/s;   4453 sec\n",
            "[2021-04-03 20:32:33,785 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.135.bert.pt, number of examples: 1999\n",
            "[2021-04-03 20:33:05,186 INFO] Step 3450/50000; xent: 3.08; lr: 0.0000069;  15 docs/s;   4519 sec\n",
            "[2021-04-03 20:34:10,261 INFO] Step 3500/50000; xent: 2.94; lr: 0.0000070;  16 docs/s;   4584 sec\n",
            "[2021-04-03 20:35:15,988 INFO] Step 3550/50000; xent: 3.00; lr: 0.0000071;  16 docs/s;   4649 sec\n",
            "[2021-04-03 20:36:21,632 INFO] Step 3600/50000; xent: 3.02; lr: 0.0000072;  16 docs/s;   4715 sec\n",
            "[2021-04-03 20:36:43,052 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.71.bert.pt, number of examples: 1999\n",
            "[2021-04-03 20:37:27,767 INFO] Step 3650/50000; xent: 3.05; lr: 0.0000073;  16 docs/s;   4781 sec\n",
            "[2021-04-03 20:38:32,838 INFO] Step 3700/50000; xent: 2.99; lr: 0.0000074;  16 docs/s;   4846 sec\n",
            "[2021-04-03 20:39:38,668 INFO] Step 3750/50000; xent: 3.03; lr: 0.0000075;  16 docs/s;   4912 sec\n",
            "[2021-04-03 20:40:43,483 INFO] Step 3800/50000; xent: 3.09; lr: 0.0000076;  16 docs/s;   4977 sec\n",
            "[2021-04-03 20:40:52,431 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.9.bert.pt, number of examples: 1999\n",
            "[2021-04-03 20:41:49,957 INFO] Step 3850/50000; xent: 2.94; lr: 0.0000077;  16 docs/s;   5043 sec\n",
            "[2021-04-03 20:42:55,048 INFO] Step 3900/50000; xent: 2.99; lr: 0.0000078;  16 docs/s;   5108 sec\n",
            "[2021-04-03 20:44:00,368 INFO] Step 3950/50000; xent: 2.94; lr: 0.0000079;  17 docs/s;   5174 sec\n",
            "[2021-04-03 20:45:02,429 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.105.bert.pt, number of examples: 2001\n",
            "[2021-04-03 20:45:06,398 INFO] Step 4000/50000; xent: 3.04; lr: 0.0000080;  16 docs/s;   5240 sec\n",
            "[2021-04-03 20:45:06,413 INFO] Saving checkpoint /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_4000.pt\n",
            "[2021-04-03 20:46:17,501 INFO] Step 4050/50000; xent: 2.92; lr: 0.0000081;  15 docs/s;   5311 sec\n",
            "[2021-04-03 20:47:22,783 INFO] Step 4100/50000; xent: 2.98; lr: 0.0000082;  16 docs/s;   5376 sec\n",
            "[2021-04-03 20:48:27,863 INFO] Step 4150/50000; xent: 2.92; lr: 0.0000083;  16 docs/s;   5441 sec\n",
            "[2021-04-03 20:49:16,913 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.50.bert.pt, number of examples: 2001\n",
            "[2021-04-03 20:49:33,859 INFO] Step 4200/50000; xent: 2.92; lr: 0.0000084;  16 docs/s;   5507 sec\n",
            "[2021-04-03 20:50:38,977 INFO] Step 4250/50000; xent: 2.91; lr: 0.0000085;  16 docs/s;   5572 sec\n",
            "[2021-04-03 20:51:44,641 INFO] Step 4300/50000; xent: 3.00; lr: 0.0000086;  16 docs/s;   5638 sec\n",
            "[2021-04-03 20:52:49,706 INFO] Step 4350/50000; xent: 2.99; lr: 0.0000087;  16 docs/s;   5703 sec\n",
            "[2021-04-03 20:53:25,836 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.106.bert.pt, number of examples: 1999\n",
            "[2021-04-03 20:53:55,980 INFO] Step 4400/50000; xent: 2.93; lr: 0.0000088;  16 docs/s;   5769 sec\n",
            "[2021-04-03 20:55:01,254 INFO] Step 4450/50000; xent: 2.98; lr: 0.0000089;  16 docs/s;   5835 sec\n",
            "[2021-04-03 20:56:06,542 INFO] Step 4500/50000; xent: 2.96; lr: 0.0000090;  16 docs/s;   5900 sec\n",
            "[2021-04-03 20:57:12,313 INFO] Step 4550/50000; xent: 2.83; lr: 0.0000091;  16 docs/s;   5966 sec\n",
            "[2021-04-03 20:57:35,328 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.38.bert.pt, number of examples: 2001\n",
            "[2021-04-03 20:58:17,951 INFO] Step 4600/50000; xent: 2.97; lr: 0.0000092;  16 docs/s;   6031 sec\n",
            "[2021-04-03 20:59:23,669 INFO] Step 4650/50000; xent: 2.88; lr: 0.0000093;  16 docs/s;   6097 sec\n",
            "[2021-04-03 21:00:29,299 INFO] Step 4700/50000; xent: 2.90; lr: 0.0000094;  16 docs/s;   6163 sec\n",
            "[2021-04-03 21:01:34,797 INFO] Step 4750/50000; xent: 2.84; lr: 0.0000095;  16 docs/s;   6228 sec\n",
            "[2021-04-03 21:01:46,543 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.24.bert.pt, number of examples: 2001\n",
            "[2021-04-03 21:02:41,530 INFO] Step 4800/50000; xent: 2.85; lr: 0.0000096;  16 docs/s;   6295 sec\n",
            "[2021-04-03 21:03:47,028 INFO] Step 4850/50000; xent: 2.87; lr: 0.0000097;  16 docs/s;   6360 sec\n",
            "[2021-04-03 21:04:52,385 INFO] Step 4900/50000; xent: 2.90; lr: 0.0000098;  16 docs/s;   6426 sec\n",
            "[2021-04-03 21:05:57,074 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.143.bert.pt, number of examples: 1084\n",
            "[2021-04-03 21:05:58,430 INFO] Step 4950/50000; xent: 2.85; lr: 0.0000099;  16 docs/s;   6492 sec\n",
            "[2021-04-03 21:07:03,921 INFO] Step 5000/50000; xent: 2.97; lr: 0.0000100;  16 docs/s;   6557 sec\n",
            "[2021-04-03 21:07:03,923 INFO] Saving checkpoint /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_5000.pt\n",
            "[2021-04-03 21:08:14,833 INFO] Step 5050/50000; xent: 2.91; lr: 0.0000101;  15 docs/s;   6628 sec\n",
            "[2021-04-03 21:08:18,376 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.94.bert.pt, number of examples: 2001\n",
            "[2021-04-03 21:09:20,920 INFO] Step 5100/50000; xent: 2.92; lr: 0.0000102;  16 docs/s;   6694 sec\n",
            "[2021-04-03 21:10:26,217 INFO] Step 5150/50000; xent: 2.88; lr: 0.0000103;  16 docs/s;   6760 sec\n",
            "[2021-04-03 21:11:31,425 INFO] Step 5200/50000; xent: 2.91; lr: 0.0000104;  16 docs/s;   6825 sec\n",
            "[2021-04-03 21:12:28,675 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.62.bert.pt, number of examples: 2001\n",
            "[2021-04-03 21:12:37,894 INFO] Step 5250/50000; xent: 2.88; lr: 0.0000105;  16 docs/s;   6891 sec\n",
            "[2021-04-03 21:13:43,720 INFO] Step 5300/50000; xent: 2.88; lr: 0.0000106;  16 docs/s;   6957 sec\n",
            "[2021-04-03 21:14:48,997 INFO] Step 5350/50000; xent: 2.86; lr: 0.0000107;  16 docs/s;   7022 sec\n",
            "[2021-04-03 21:15:54,117 INFO] Step 5400/50000; xent: 2.85; lr: 0.0000108;  16 docs/s;   7088 sec\n",
            "[2021-04-03 21:16:37,975 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.139.bert.pt, number of examples: 2001\n",
            "[2021-04-03 21:17:00,353 INFO] Step 5450/50000; xent: 2.94; lr: 0.0000109;  16 docs/s;   7154 sec\n",
            "[2021-04-03 21:18:05,492 INFO] Step 5500/50000; xent: 2.86; lr: 0.0000110;  16 docs/s;   7219 sec\n",
            "[2021-04-03 21:19:10,869 INFO] Step 5550/50000; xent: 2.81; lr: 0.0000111;  16 docs/s;   7284 sec\n",
            "[2021-04-03 21:20:16,247 INFO] Step 5600/50000; xent: 2.87; lr: 0.0000112;  16 docs/s;   7350 sec\n",
            "[2021-04-03 21:20:46,753 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.88.bert.pt, number of examples: 1999\n",
            "[2021-04-03 21:21:22,083 INFO] Step 5650/50000; xent: 2.92; lr: 0.0000113;  16 docs/s;   7415 sec\n",
            "[2021-04-03 21:22:27,514 INFO] Step 5700/50000; xent: 2.82; lr: 0.0000114;  16 docs/s;   7481 sec\n",
            "[2021-04-03 21:23:32,709 INFO] Step 5750/50000; xent: 2.93; lr: 0.0000115;  16 docs/s;   7546 sec\n",
            "[2021-04-03 21:24:38,069 INFO] Step 5800/50000; xent: 2.86; lr: 0.0000116;  16 docs/s;   7611 sec\n",
            "[2021-04-03 21:24:56,790 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.92.bert.pt, number of examples: 2000\n",
            "[2021-04-03 21:25:43,509 INFO] Step 5850/50000; xent: 2.87; lr: 0.0000117;  16 docs/s;   7677 sec\n",
            "[2021-04-03 21:26:49,181 INFO] Step 5900/50000; xent: 2.75; lr: 0.0000118;  16 docs/s;   7743 sec\n",
            "[2021-04-03 21:27:54,863 INFO] Step 5950/50000; xent: 2.86; lr: 0.0000119;  16 docs/s;   7808 sec\n",
            "[2021-04-03 21:29:00,046 INFO] Step 6000/50000; xent: 2.81; lr: 0.0000120;  16 docs/s;   7873 sec\n",
            "[2021-04-03 21:29:00,048 INFO] Saving checkpoint /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_6000.pt\n",
            "[2021-04-03 21:29:13,031 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.68.bert.pt, number of examples: 1999\n",
            "[2021-04-03 21:30:12,350 INFO] Step 6050/50000; xent: 2.84; lr: 0.0000121;  15 docs/s;   7946 sec\n",
            "[2021-04-03 21:31:17,389 INFO] Step 6100/50000; xent: 2.87; lr: 0.0000122;  16 docs/s;   8011 sec\n",
            "[2021-04-03 21:32:21,998 INFO] Step 6150/50000; xent: 2.83; lr: 0.0000123;  16 docs/s;   8075 sec\n",
            "[2021-04-03 21:33:21,581 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.0.bert.pt, number of examples: 2001\n",
            "[2021-04-03 21:33:28,092 INFO] Step 6200/50000; xent: 2.89; lr: 0.0000124;  16 docs/s;   8141 sec\n",
            "[2021-04-03 21:34:33,537 INFO] Step 6250/50000; xent: 2.85; lr: 0.0000125;  16 docs/s;   8207 sec\n",
            "[2021-04-03 21:35:39,250 INFO] Step 6300/50000; xent: 2.85; lr: 0.0000126;  16 docs/s;   8273 sec\n",
            "[2021-04-03 21:36:43,854 INFO] Step 6350/50000; xent: 2.85; lr: 0.0000127;  16 docs/s;   8337 sec\n",
            "[2021-04-03 21:37:32,040 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.83.bert.pt, number of examples: 1999\n",
            "[2021-04-03 21:37:50,416 INFO] Step 6400/50000; xent: 2.83; lr: 0.0000128;  16 docs/s;   8404 sec\n",
            "[2021-04-03 21:38:56,071 INFO] Step 6450/50000; xent: 2.83; lr: 0.0000129;  16 docs/s;   8469 sec\n",
            "[2021-04-03 21:40:01,108 INFO] Step 6500/50000; xent: 2.85; lr: 0.0000130;  16 docs/s;   8535 sec\n",
            "[2021-04-03 21:41:06,530 INFO] Step 6550/50000; xent: 2.88; lr: 0.0000131;  16 docs/s;   8600 sec\n",
            "[2021-04-03 21:41:41,768 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.138.bert.pt, number of examples: 2000\n",
            "[2021-04-03 21:42:13,275 INFO] Step 6600/50000; xent: 2.79; lr: 0.0000132;  16 docs/s;   8667 sec\n",
            "[2021-04-03 21:43:18,864 INFO] Step 6650/50000; xent: 2.80; lr: 0.0000133;  16 docs/s;   8732 sec\n",
            "[2021-04-03 21:44:24,409 INFO] Step 6700/50000; xent: 2.82; lr: 0.0000134;  16 docs/s;   8798 sec\n",
            "[2021-04-03 21:45:29,187 INFO] Step 6750/50000; xent: 2.80; lr: 0.0000135;  16 docs/s;   8863 sec\n",
            "[2021-04-03 21:45:52,124 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.72.bert.pt, number of examples: 2000\n",
            "[2021-04-03 21:46:35,179 INFO] Step 6800/50000; xent: 2.86; lr: 0.0000136;  16 docs/s;   8929 sec\n",
            "[2021-04-03 21:47:40,211 INFO] Step 6850/50000; xent: 2.84; lr: 0.0000137;  16 docs/s;   8994 sec\n",
            "[2021-04-03 21:48:45,637 INFO] Step 6900/50000; xent: 2.79; lr: 0.0000138;  17 docs/s;   9059 sec\n",
            "[2021-04-03 21:49:50,862 INFO] Step 6950/50000; xent: 2.75; lr: 0.0000139;  16 docs/s;   9124 sec\n",
            "[2021-04-03 21:50:00,741 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.89.bert.pt, number of examples: 2001\n",
            "[2021-04-03 21:50:56,905 INFO] Step 7000/50000; xent: 2.89; lr: 0.0000140;  16 docs/s;   9190 sec\n",
            "[2021-04-03 21:50:56,921 INFO] Saving checkpoint /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_7000.pt\n",
            "[2021-04-03 21:52:07,793 INFO] Step 7050/50000; xent: 2.76; lr: 0.0000141;  15 docs/s;   9261 sec\n",
            "[2021-04-03 21:53:13,103 INFO] Step 7100/50000; xent: 2.83; lr: 0.0000142;  16 docs/s;   9326 sec\n",
            "[2021-04-03 21:54:14,086 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.51.bert.pt, number of examples: 2000\n",
            "[2021-04-03 21:54:19,326 INFO] Step 7150/50000; xent: 2.79; lr: 0.0000143;  16 docs/s;   9393 sec\n",
            "[2021-04-03 21:55:24,834 INFO] Step 7200/50000; xent: 2.78; lr: 0.0000144;  16 docs/s;   9458 sec\n",
            "[2021-04-03 21:56:29,759 INFO] Step 7250/50000; xent: 2.79; lr: 0.0000145;  16 docs/s;   9523 sec\n",
            "[2021-04-03 21:57:34,944 INFO] Step 7300/50000; xent: 2.87; lr: 0.0000146;  16 docs/s;   9588 sec\n",
            "[2021-04-03 21:58:23,977 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.35.bert.pt, number of examples: 1998\n",
            "[2021-04-03 21:58:40,999 INFO] Step 7350/50000; xent: 2.91; lr: 0.0000147;  16 docs/s;   9654 sec\n",
            "[2021-04-03 21:59:46,045 INFO] Step 7400/50000; xent: 2.83; lr: 0.0000148;  16 docs/s;   9719 sec\n",
            "[2021-04-03 22:00:51,173 INFO] Step 7450/50000; xent: 2.78; lr: 0.0000149;  17 docs/s;   9785 sec\n",
            "[2021-04-03 22:01:56,597 INFO] Step 7500/50000; xent: 2.87; lr: 0.0000150;  16 docs/s;   9850 sec\n",
            "[2021-04-03 22:02:34,410 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.37.bert.pt, number of examples: 1999\n",
            "[2021-04-03 22:03:03,468 INFO] Step 7550/50000; xent: 2.82; lr: 0.0000151;  16 docs/s;   9917 sec\n",
            "[2021-04-03 22:04:08,703 INFO] Step 7600/50000; xent: 2.77; lr: 0.0000152;  16 docs/s;   9982 sec\n",
            "[2021-04-03 22:05:13,626 INFO] Step 7650/50000; xent: 2.77; lr: 0.0000153;  16 docs/s;  10047 sec\n",
            "[2021-04-03 22:06:18,838 INFO] Step 7700/50000; xent: 2.86; lr: 0.0000154;  16 docs/s;  10112 sec\n",
            "[2021-04-03 22:06:41,905 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.80.bert.pt, number of examples: 1999\n",
            "[2021-04-03 22:07:25,078 INFO] Step 7750/50000; xent: 2.73; lr: 0.0000155;  16 docs/s;  10178 sec\n",
            "[2021-04-03 22:08:30,852 INFO] Step 7800/50000; xent: 2.81; lr: 0.0000156;  16 docs/s;  10244 sec\n",
            "[2021-04-03 22:09:35,908 INFO] Step 7850/50000; xent: 2.81; lr: 0.0000157;  16 docs/s;  10309 sec\n",
            "[2021-04-03 22:10:40,757 INFO] Step 7900/50000; xent: 2.82; lr: 0.0000158;  16 docs/s;  10374 sec\n",
            "[2021-04-03 22:10:50,853 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.52.bert.pt, number of examples: 2001\n",
            "[2021-04-03 22:11:47,175 INFO] Step 7950/50000; xent: 2.81; lr: 0.0000159;  16 docs/s;  10441 sec\n",
            "[2021-04-03 22:12:52,937 INFO] Step 8000/50000; xent: 2.82; lr: 0.0000160;  17 docs/s;  10506 sec\n",
            "[2021-04-03 22:12:52,954 INFO] Saving checkpoint /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_8000.pt\n",
            "[2021-04-03 22:14:03,929 INFO] Step 8050/50000; xent: 2.94; lr: 0.0000161;  15 docs/s;  10577 sec\n",
            "[2021-04-03 22:15:06,098 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.12.bert.pt, number of examples: 2001\n",
            "[2021-04-03 22:15:10,119 INFO] Step 8100/50000; xent: 2.87; lr: 0.0000162;  16 docs/s;  10644 sec\n",
            "[2021-04-03 22:16:15,775 INFO] Step 8150/50000; xent: 2.85; lr: 0.0000163;  16 docs/s;  10709 sec\n",
            "[2021-04-03 22:17:20,866 INFO] Step 8200/50000; xent: 2.83; lr: 0.0000164;  17 docs/s;  10774 sec\n",
            "[2021-04-03 22:18:26,096 INFO] Step 8250/50000; xent: 2.86; lr: 0.0000165;  16 docs/s;  10839 sec\n",
            "[2021-04-03 22:19:16,411 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.114.bert.pt, number of examples: 1998\n",
            "[2021-04-03 22:19:32,157 INFO] Step 8300/50000; xent: 2.97; lr: 0.0000166;  16 docs/s;  10906 sec\n",
            "[2021-04-03 22:20:37,385 INFO] Step 8350/50000; xent: 2.77; lr: 0.0000167;  16 docs/s;  10971 sec\n",
            "[2021-04-03 22:21:43,290 INFO] Step 8400/50000; xent: 2.83; lr: 0.0000168;  16 docs/s;  11037 sec\n",
            "[2021-04-03 22:22:48,606 INFO] Step 8450/50000; xent: 2.85; lr: 0.0000169;  16 docs/s;  11102 sec\n",
            "[2021-04-03 22:23:25,696 INFO] Loading train dataset from /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm.train.86.bert.pt, number of examples: 1999\n",
            "[2021-04-03 22:23:54,455 INFO] Step 8500/50000; xent: 2.82; lr: 0.0000170;  16 docs/s;  11168 sec\n",
            "[2021-04-03 22:24:59,846 INFO] Step 8550/50000; xent: 2.75; lr: 0.0000171;  16 docs/s;  11233 sec\n",
            "[2021-04-03 22:26:05,482 INFO] Step 8600/50000; xent: 2.75; lr: 0.0000172;  16 docs/s;  11299 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4sHdbTN6IE3"
      },
      "source": [
        "## TASK 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA-hIiIc6K7R"
      },
      "source": [
        "Train the models and plot the relevant metrics(loss/F1/accuracy/etc) with respect to epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6fRDRDoar8T"
      },
      "source": [
        "\"\"\"\n",
        " Generated using Tensorboard \n",
        "!tensorboard --logdirs = <MODEL_PATH> \n",
        "<MODEL_PATH> corresponds to the path of the trained model. \n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91PDRVWBe9F0"
      },
      "source": [
        "[Plots](https://drive.google.com/drive/u/1/folders/1H_NFA59HUKC1jH_tJRk7dsdMEUhQz_CS)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoJQX_Ai6OTv"
      },
      "source": [
        "## TASK 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ-7GHJ96T3n"
      },
      "source": [
        "Compute and report the Rouge scores for your trained model (results do not have to be the same as the paper)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B3zM8uC8IdK",
        "outputId": "14696fa5-e031-4ecd-f08a-c25712a89f0c"
      },
      "source": [
        "cd  /content/drive/MyDrive/nlpyang/PreSumm-master/src"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1veaxwqyZvvFioYNDI_lezmN1zGiPBSEh/nlpyang/PreSumm-master/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnmGq3M-ExnP",
        "outputId": "76d0be03-1cba-480f-9837-5272eede4113"
      },
      "source": [
        "!python /content/drive/MyDrive/nlpyang/PreSumm-master/src/train.py -task abs -mode test -batch_size 3000 -test_batch_size 50 -bert_data_path /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/ad_test/cnndm -log_file /content/drive/MyDrive/nlpyang/PreSumm-master/logs/val_abs_bert_cnndm -model_path /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH -test_from /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_10000.pt -sep_optim true -use_interval true -visible_gpus 0 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path /logs/abs_bert_cnndm \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-04-09 14:49:13,128 INFO] Loading checkpoint from /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_10000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='/content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/ad_test/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='/content/drive/MyDrive/nlpyang/PreSumm-master/logs/val_abs_bert_cnndm', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='/content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='/logs/abs_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='../temp', test_all=False, test_batch_size=50, test_from='/content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_10000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='0', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-04-09 14:49:16,091 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "[2021-04-09 14:49:16,093 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[2021-04-09 14:49:16,470 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/nlpyang/PreSumm-master/src/train.py\", line 135, in <module>\n",
            "    test_abs(args, device_id, cp, step)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1veaxwqyZvvFioYNDI_lezmN1zGiPBSEh/nlpyang/PreSumm-master/src/train_abstractive.py\", line 215, in test_abs\n",
            "    model = AbsSummarizer(args, device, checkpoint)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1veaxwqyZvvFioYNDI_lezmN1zGiPBSEh/nlpyang/PreSumm-master/src/models/model_builder.py\", line 217, in __init__\n",
            "    self.load_state_dict(checkpoint['model'], strict=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 777, in load_state_dict\n",
            "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
            "RuntimeError: Error(s) in loading state_dict for AbsSummarizer:\n",
            "\tMissing key(s) in state_dict: \"decoder.embeddings.weight\", \"decoder.pos_emb.pe\", \"decoder.transformer_layers.0.mask\", \"decoder.transformer_layers.0.self_attn.linear_keys.weight\", \"decoder.transformer_layers.0.self_attn.linear_keys.bias\", \"decoder.transformer_layers.0.self_attn.linear_values.weight\", \"decoder.transformer_layers.0.self_attn.linear_values.bias\", \"decoder.transformer_layers.0.self_attn.linear_query.weight\", \"decoder.transformer_layers.0.self_attn.linear_query.bias\", \"decoder.transformer_layers.0.self_attn.final_linear.weight\", \"decoder.transformer_layers.0.self_attn.final_linear.bias\", \"decoder.transformer_layers.0.context_attn.linear_keys.weight\", \"decoder.transformer_layers.0.context_attn.linear_keys.bias\", \"decoder.transformer_layers.0.context_attn.linear_values.weight\", \"decoder.transformer_layers.0.context_attn.linear_values.bias\", \"decoder.transformer_layers.0.context_attn.linear_query.weight\", \"decoder.transformer_layers.0.context_attn.linear_query.bias\", \"decoder.transformer_layers.0.context_attn.final_linear.weight\", \"decoder.transformer_layers.0.context_attn.final_linear.bias\", \"decoder.transformer_layers.0.feed_forward.w_1.weight\", \"decoder.transformer_layers.0.feed_forward.w_1.bias\", \"decoder.transformer_layers.0.feed_forward.w_2.weight\", \"decoder.transformer_layers.0.feed_forward.w_2.bias\", \"decoder.transformer_layers.0.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.0.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.0.layer_norm_1.weight\", \"decoder.transformer_layers.0.layer_norm_1.bias\", \"decoder.transformer_layers.0.layer_norm_2.weight\", \"decoder.transformer_layers.0.layer_norm_2.bias\", \"decoder.transformer_layers.1.mask\", \"decoder.transformer_layers.1.self_attn.linear_keys.weight\", \"decoder.transformer_layers.1.self_attn.linear_keys.bias\", \"decoder.transformer_layers.1.self_attn.linear_values.weight\", \"decoder.transformer_layers.1.self_attn.linear_values.bias\", \"decoder.transformer_layers.1.self_attn.linear_query.weight\", \"decoder.transformer_layers.1.self_attn.linear_query.bias\", \"decoder.transformer_layers.1.self_attn.final_linear.weight\", \"decoder.transformer_layers.1.self_attn.final_linear.bias\", \"decoder.transformer_layers.1.context_attn.linear_keys.weight\", \"decoder.transformer_layers.1.context_attn.linear_keys.bias\", \"decoder.transformer_layers.1.context_attn.linear_values.weight\", \"decoder.transformer_layers.1.context_attn.linear_values.bias\", \"decoder.transformer_layers.1.context_attn.linear_query.weight\", \"decoder.transformer_layers.1.context_attn.linear_query.bias\", \"decoder.transformer_layers.1.context_attn.final_linear.weight\", \"decoder.transformer_layers.1.context_attn.final_linear.bias\", \"decoder.transformer_layers.1.feed_forward.w_1.weight\", \"decoder.transformer_layers.1.feed_forward.w_1.bias\", \"decoder.transformer_layers.1.feed_forward.w_2.weight\", \"decoder.transformer_layers.1.feed_forward.w_2.bias\", \"decoder.transformer_layers.1.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.1.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.1.layer_norm_1.weight\", \"decoder.transformer_layers.1.layer_norm_1.bias\", \"decoder.transformer_layers.1.layer_norm_2.weight\", \"decoder.transformer_layers.1.layer_norm_2.bias\", \"decoder.transformer_layers.2.mask\", \"decoder.transformer_layers.2.self_attn.linear_keys.weight\", \"decoder.transformer_layers.2.self_attn.linear_keys.bias\", \"decoder.transformer_layers.2.self_attn.linear_values.weight\", \"decoder.transformer_layers.2.self_attn.linear_values.bias\", \"decoder.transformer_layers.2.self_attn.linear_query.weight\", \"decoder.transformer_layers.2.self_attn.linear_query.bias\", \"decoder.transformer_layers.2.self_attn.final_linear.weight\", \"decoder.transformer_layers.2.self_attn.final_linear.bias\", \"decoder.transformer_layers.2.context_attn.linear_keys.weight\", \"decoder.transformer_layers.2.context_attn.linear_keys.bias\", \"decoder.transformer_layers.2.context_attn.linear_values.weight\", \"decoder.transformer_layers.2.context_attn.linear_values.bias\", \"decoder.transformer_layers.2.context_attn.linear_query.weight\", \"decoder.transformer_layers.2.context_attn.linear_query.bias\", \"decoder.transformer_layers.2.context_attn.final_linear.weight\", \"decoder.transformer_layers.2.context_attn.final_linear.bias\", \"decoder.transformer_layers.2.feed_forward.w_1.weight\", \"decoder.transformer_layers.2.feed_forward.w_1.bias\", \"decoder.transformer_layers.2.feed_forward.w_2.weight\", \"decoder.transformer_layers.2.feed_forward.w_2.bias\", \"decoder.transformer_layers.2.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.2.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.2.layer_norm_1.weight\", \"decoder.transformer_layers.2.layer_norm_1.bias\", \"decoder.transformer_layers.2.layer_norm_2.weight\", \"decoder.transformer_layers.2.layer_norm_2.bias\", \"decoder.transformer_layers.3.mask\", \"decoder.transformer_layers.3.self_attn.linear_keys.weight\", \"decoder.transformer_layers.3.self_attn.linear_keys.bias\", \"decoder.transformer_layers.3.self_attn.linear_values.weight\", \"decoder.transformer_layers.3.self_attn.linear_values.bias\", \"decoder.transformer_layers.3.self_attn.linear_query.weight\", \"decoder.transformer_layers.3.self_attn.linear_query.bias\", \"decoder.transformer_layers.3.self_attn.final_linear.weight\", \"decoder.transformer_layers.3.self_attn.final_linear.bias\", \"decoder.transformer_layers.3.context_attn.linear_keys.weight\", \"decoder.transformer_layers.3.context_attn.linear_keys.bias\", \"decoder.transformer_layers.3.context_attn.linear_values.weight\", \"decoder.transformer_layers.3.context_attn.linear_values.bias\", \"decoder.transformer_layers.3.context_attn.linear_query.weight\", \"decoder.transformer_layers.3.context_attn.linear_query.bias\", \"decoder.transformer_layers.3.context_attn.final_linear.weight\", \"decoder.transformer_layers.3.context_attn.final_linear.bias\", \"decoder.transformer_layers.3.feed_forward.w_1.weight\", \"decoder.transformer_layers.3.feed_forward.w_1.bias\", \"decoder.transformer_layers.3.feed_forward.w_2.weight\", \"decoder.transformer_layers.3.feed_forward.w_2.bias\", \"decoder.transformer_layers.3.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.3.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.3.layer_norm_1.weight\", \"decoder.transformer_layers.3.layer_norm_1.bias\", \"decoder.transformer_layers.3.layer_norm_2.weight\", \"decoder.transformer_layers.3.layer_norm_2.bias\", \"decoder.transformer_layers.4.mask\", \"decoder.transformer_layers.4.self_attn.linear_keys.weight\", \"decoder.transformer_layers.4.self_attn.linear_keys.bias\", \"decoder.transformer_layers.4.self_attn.linear_values.weight\", \"decoder.transformer_layers.4.self_attn.linear_values.bias\", \"decoder.transformer_layers.4.self_attn.linear_query.weight\", \"decoder.transformer_layers.4.self_attn.linear_query.bias\", \"decoder.transformer_layers.4.self_attn.final_linear.weight\", \"decoder.transformer_layers.4.self_attn.final_linear.bias\", \"decoder.transformer_layers.4.context_attn.linear_keys.weight\", \"decoder.transformer_layers.4.context_attn.linear_keys.bias\", \"decoder.transformer_layers.4.context_attn.linear_values.weight\", \"decoder.transformer_layers.4.context_attn.linear_values.bias\", \"decoder.transformer_layers.4.context_attn.linear_query.weight\", \"decoder.transformer_layers.4.context_attn.linear_query.bias\", \"decoder.transformer_layers.4.context_attn.final_linear.weight\", \"decoder.transformer_layers.4.context_attn.final_linear.bias\", \"decoder.transformer_layers.4.feed_forward.w_1.weight\", \"decoder.transformer_layers.4.feed_forward.w_1.bias\", \"decoder.transformer_layers.4.feed_forward.w_2.weight\", \"decoder.transformer_layers.4.feed_forward.w_2.bias\", \"decoder.transformer_layers.4.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.4.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.4.layer_norm_1.weight\", \"decoder.transformer_layers.4.layer_norm_1.bias\", \"decoder.transformer_layers.4.layer_norm_2.weight\", \"decoder.transformer_layers.4.layer_norm_2.bias\", \"decoder.transformer_layers.5.mask\", \"decoder.transformer_layers.5.self_attn.linear_keys.weight\", \"decoder.transformer_layers.5.self_attn.linear_keys.bias\", \"decoder.transformer_layers.5.self_attn.linear_values.weight\", \"decoder.transformer_layers.5.self_attn.linear_values.bias\", \"decoder.transformer_layers.5.self_attn.linear_query.weight\", \"decoder.transformer_layers.5.self_attn.linear_query.bias\", \"decoder.transformer_layers.5.self_attn.final_linear.weight\", \"decoder.transformer_layers.5.self_attn.final_linear.bias\", \"decoder.transformer_layers.5.context_attn.linear_keys.weight\", \"decoder.transformer_layers.5.context_attn.linear_keys.bias\", \"decoder.transformer_layers.5.context_attn.linear_values.weight\", \"decoder.transformer_layers.5.context_attn.linear_values.bias\", \"decoder.transformer_layers.5.context_attn.linear_query.weight\", \"decoder.transformer_layers.5.context_attn.linear_query.bias\", \"decoder.transformer_layers.5.context_attn.final_linear.weight\", \"decoder.transformer_layers.5.context_attn.final_linear.bias\", \"decoder.transformer_layers.5.feed_forward.w_1.weight\", \"decoder.transformer_layers.5.feed_forward.w_1.bias\", \"decoder.transformer_layers.5.feed_forward.w_2.weight\", \"decoder.transformer_layers.5.feed_forward.w_2.bias\", \"decoder.transformer_layers.5.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.5.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.5.layer_norm_1.weight\", \"decoder.transformer_layers.5.layer_norm_1.bias\", \"decoder.transformer_layers.5.layer_norm_2.weight\", \"decoder.transformer_layers.5.layer_norm_2.bias\", \"decoder.layer_norm.weight\", \"decoder.layer_norm.bias\", \"generator.0.weight\", \"generator.0.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"ext_layer.pos_emb.pe\", \"ext_layer.transformer_inter.0.self_attn.linear_keys.weight\", \"ext_layer.transformer_inter.0.self_attn.linear_keys.bias\", \"ext_layer.transformer_inter.0.self_attn.linear_values.weight\", \"ext_layer.transformer_inter.0.self_attn.linear_values.bias\", \"ext_layer.transformer_inter.0.self_attn.linear_query.weight\", \"ext_layer.transformer_inter.0.self_attn.linear_query.bias\", \"ext_layer.transformer_inter.0.self_attn.final_linear.weight\", \"ext_layer.transformer_inter.0.self_attn.final_linear.bias\", \"ext_layer.transformer_inter.0.feed_forward.w_1.weight\", \"ext_layer.transformer_inter.0.feed_forward.w_1.bias\", \"ext_layer.transformer_inter.0.feed_forward.w_2.weight\", \"ext_layer.transformer_inter.0.feed_forward.w_2.bias\", \"ext_layer.transformer_inter.0.feed_forward.layer_norm.weight\", \"ext_layer.transformer_inter.0.feed_forward.layer_norm.bias\", \"ext_layer.transformer_inter.0.layer_norm.weight\", \"ext_layer.transformer_inter.0.layer_norm.bias\", \"ext_layer.transformer_inter.1.self_attn.linear_keys.weight\", \"ext_layer.transformer_inter.1.self_attn.linear_keys.bias\", \"ext_layer.transformer_inter.1.self_attn.linear_values.weight\", \"ext_layer.transformer_inter.1.self_attn.linear_values.bias\", \"ext_layer.transformer_inter.1.self_attn.linear_query.weight\", \"ext_layer.transformer_inter.1.self_attn.linear_query.bias\", \"ext_layer.transformer_inter.1.self_attn.final_linear.weight\", \"ext_layer.transformer_inter.1.self_attn.final_linear.bias\", \"ext_layer.transformer_inter.1.feed_forward.w_1.weight\", \"ext_layer.transformer_inter.1.feed_forward.w_1.bias\", \"ext_layer.transformer_inter.1.feed_forward.w_2.weight\", \"ext_layer.transformer_inter.1.feed_forward.w_2.bias\", \"ext_layer.transformer_inter.1.feed_forward.layer_norm.weight\", \"ext_layer.transformer_inter.1.feed_forward.layer_norm.bias\", \"ext_layer.transformer_inter.1.layer_norm.weight\", \"ext_layer.transformer_inter.1.layer_norm.bias\", \"ext_layer.layer_norm.weight\", \"ext_layer.layer_norm.bias\", \"ext_layer.wo.weight\", \"ext_layer.wo.bias\". \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9tTdrPR6X_G",
        "outputId": "1bbb9c3b-f0a1-4c61-89a6-c0ac1592fd31"
      },
      "source": [
        " !python train.py -task abs -mode validate -batch_size 3000 -test_batch_size 50 -bert_data_path /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/cnndm -log_file /content/drive/MyDrive/nlpyang/PreSumm-master/logs/val_abs_bert_cnndm -model_path /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_8000.pt -sep_optim true -use_interval true -visible_gpus 0 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 124, in <module>\n",
            "    validate_abs(args, device_id)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1veaxwqyZvvFioYNDI_lezmN1zGiPBSEh/nlpyang/PreSumm-master/src/train_abstractive.py\", line 165, in validate_abs\n",
            "    time.sleep(300)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Mtta8c_-Zx"
      },
      "source": [
        "-result_path /content/drive/MyDrive/nlpyang/PreSumm-master/logs/val_abs_bert_cnndm "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32K8GCwN8xSk"
      },
      "source": [
        "## TASK 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81pK5bPQ-gj7"
      },
      "source": [
        "Select 3-4 example articles and generate their summaries using your trained model - both extractive and abstractive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbL82wkbf70O"
      },
      "source": [
        "# INPUT /content/drive/MyDrive/nlpyang/PreSumm-dev/raw_input \n",
        "# OUTPUT Abstractive: /content/drive/MyDrive/nlpyang/PreSumm-dev/logs \n",
        "#        Extractive : /content/drive/MyDrive/nlpyang/PreSumm-dev/raw_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPHEMdL_UToW"
      },
      "source": [
        "### Generating Abstractive Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxeL9w9c1w7v",
        "outputId": "308d32c1-aeff-47fb-b57b-d04cd8cd4609"
      },
      "source": [
        "cd  /content/drive/MyDrive/nlpyang/PreSumm-dev/src"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1veaxwqyZvvFioYNDI_lezmN1zGiPBSEh/nlpyang/PreSumm-dev/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWqNdHjovm2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de31218e-11fe-4d54-ad15-18263b11e7c4"
      },
      "source": [
        " !python train.py -task abs -mode test_text -batch_size 3000 -test_batch_size 500 -model_path /content/drive/MyDrive/nlpyang/PreSumm-dev/MODEL_PATH -sep_optim true -use_interval true -visible_gpus 0 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path /content/drive/MyDrive/nlpyang/PreSumm-dev/logs/Abstractive_5/abs_bert_cnndm -text_src /content/drive/MyDrive/nlpyang/PreSumm-dev/raw_input/input5_abs_navigation_amazon_kindle.txt.data  -test_from /content/drive/MyDrive/nlpyang/PreSumm-dev/MODEL_PATH/model_step_8000.pt  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [-task {ext,abs}] [-encoder {bert,baseline}]\n",
            "                [-mode {train,validate,test}] [-bert_data_path BERT_DATA_PATH]\n",
            "                [-model_path MODEL_PATH] [-result_path RESULT_PATH]\n",
            "                [-temp_dir TEMP_DIR] [-batch_size BATCH_SIZE]\n",
            "                [-test_batch_size TEST_BATCH_SIZE] [-max_pos MAX_POS]\n",
            "                [-use_interval [USE_INTERVAL]] [-large [LARGE]]\n",
            "                [-load_from_extractive LOAD_FROM_EXTRACTIVE]\n",
            "                [-sep_optim [SEP_OPTIM]] [-lr_bert LR_BERT] [-lr_dec LR_DEC]\n",
            "                [-use_bert_emb [USE_BERT_EMB]] [-share_emb [SHARE_EMB]]\n",
            "                [-finetune_bert [FINETUNE_BERT]] [-dec_dropout DEC_DROPOUT]\n",
            "                [-dec_layers DEC_LAYERS] [-dec_hidden_size DEC_HIDDEN_SIZE]\n",
            "                [-dec_heads DEC_HEADS] [-dec_ff_size DEC_FF_SIZE]\n",
            "                [-enc_hidden_size ENC_HIDDEN_SIZE] [-enc_ff_size ENC_FF_SIZE]\n",
            "                [-enc_dropout ENC_DROPOUT] [-enc_layers ENC_LAYERS]\n",
            "                [-ext_dropout EXT_DROPOUT] [-ext_layers EXT_LAYERS]\n",
            "                [-ext_hidden_size EXT_HIDDEN_SIZE] [-ext_heads EXT_HEADS]\n",
            "                [-ext_ff_size EXT_FF_SIZE] [-label_smoothing LABEL_SMOOTHING]\n",
            "                [-generator_shard_size GENERATOR_SHARD_SIZE] [-alpha ALPHA]\n",
            "                [-beam_size BEAM_SIZE] [-min_length MIN_LENGTH]\n",
            "                [-max_length MAX_LENGTH] [-max_tgt_len MAX_TGT_LEN]\n",
            "                [-param_init PARAM_INIT]\n",
            "                [-param_init_glorot [PARAM_INIT_GLOROT]] [-optim OPTIM]\n",
            "                [-lr LR] [-beta1 BETA1] [-beta2 BETA2]\n",
            "                [-warmup_steps WARMUP_STEPS]\n",
            "                [-warmup_steps_bert WARMUP_STEPS_BERT]\n",
            "                [-warmup_steps_dec WARMUP_STEPS_DEC]\n",
            "                [-max_grad_norm MAX_GRAD_NORM]\n",
            "                [-save_checkpoint_steps SAVE_CHECKPOINT_STEPS]\n",
            "                [-accum_count ACCUM_COUNT] [-report_every REPORT_EVERY]\n",
            "                [-train_steps TRAIN_STEPS] [-recall_eval [RECALL_EVAL]]\n",
            "                [-visible_gpus VISIBLE_GPUS] [-gpu_ranks GPU_RANKS]\n",
            "                [-log_file LOG_FILE] [-seed SEED] [-test_all [TEST_ALL]]\n",
            "                [-test_from TEST_FROM] [-test_start_from TEST_START_FROM]\n",
            "                [-train_from TRAIN_FROM] [-report_rouge [REPORT_ROUGE]]\n",
            "                [-block_trigram [BLOCK_TRIGRAM]]\n",
            "train.py: error: argument -mode: invalid choice: 'test_text' (choose from 'train', 'validate', 'test')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9RU4AAxkKHT"
      },
      "source": [
        "#-text_tgt /content/drive/MyDrive/nlpyang/PreSumm-dev/raw_input/checkinput1.txt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmK5sqUaaaVm"
      },
      "source": [
        "Output Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hNykOUhadJI"
      },
      "source": [
        "\"\"\"\n",
        "INPUT 1  (PreSumm-dev --> raw_input --> input1_abs.txt)\n",
        "this Terry Jones had a love of the absurd that contributed much to the anarchic humour of Monty Python's Flying Circus. His style of visual comedy, leavened with a touch of the surreal, inspired many comedians who followed him. It was on Python that he honed his directing skills, notably on Life of Brian and The Meaning of Life. A keen historian, he wrote a number of books and fronted TV documentaries on ancient and medieval history. Terence Graham Parry Jones was born in Colwyn Bay in north Wales on 1 February 1942. His grandparents ran the local amateur operatic society and staged Gilbert and Sullivan concerts on the town's pier each year His family moved to Surrey when he was four but he always felt nostalgic about his native land. \"I couldn't bear it and for the longest time I wanted Wales back,\" he once said. \"I still feel very Welsh and feel it's where I should be really.\" After leaving the Royal Grammar School in Guildford, where he captained the school, he went on to read English at St Edmund Hall, Oxford. However, as he put it, he \"strayed into history\", the subject in which he graduated. While at Oxford he wrote sketches for the Oxford Revue and performed alongside a fellow student, Michael Palin.\n",
        "(CNN) An Iranian chess referee says she is frightened to return home after she was criticized online for not wearing the appropriate headscarf during an international tournament. Currently the chief adjudicator at the Women's World Chess Championship held in Russia and China, Shohreh Bayat says she fears arrest after a photograph of her was taken during the event and was then circulated online in Iran. \"They are very sensitive about the hijab when we are representing Iran in international events and even sometimes they send a person with the team to control our hijab,\" Bayat told CNN Sport in a phone interview Tuesday. The headscarf, or the hijab, has been a mandatory part of women's dress in Iran since the 1979 Islamic revolution but, in recent years, some women have mounted opposition and staged protests about headwear rules. Bayat said she had been wearing a headscarf at the tournament but that certain camera angles had made it look like she was not. \"If I come back to Iran, I think there are a few possibilities. It is highly possible that they arrest me [...] or it is possible that they invalidate my passport,\" added Bayat. \"I think they want to make an example of me.\" The photographs were taken at the first stage of the chess championship in Shanghai, China, but Bayat has since flown to Vladivostok, Russia, for the second leg between Ju Wenjun and Aleksandra Goryachkina. She was left \"panicked and shocked\" when she became aware of the reaction in Iran after checking her phone in the hotel room. The 32-year-old said she felt helpless as websites reportedly condemned her for what some described as protesting the country's compulsory law. Subsequently, Bayat has decided to no longer wear the headscarf. \"I'm not wearing it anymore because what is the point? I was just tolerating it, I don't believe in the hijab,\" she added. \"People must be free to choose to wear what they want, and I was only wearing the hijab because I live in Iran and I had to wear it. I had no other choice.\" Bayat says she sought help from the country's chess federation. She says the federation told her to post an apology on her social media channels. She agreed under the condition that the federation would guarantee her safety but she said they refused. \"My husband is in Iran, my parents are in Iran, all my family members are in Iran. I don't have anyone else outside of Iran. I don't know what to say, this is a very hard situation,\" she said. CNN contacted the Iranian Chess Federation on Tuesday but has yet to receive a response.\n",
        "\n",
        "OUTPUT 1 (Abstractively summarized) (Presumm-dev --> logs --> Abtractive_1 --> abs_bert_cnndn.-1.gold)\n",
        "this Terry Jones had a love of the absurd that contributed much to the anarchic humour of Monty Python's Flying Circus.\n",
        "An Iranian chess referee says she is frightened to return home after she was criticized online for not wearing the appropriate headscarf during an international tournament.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_prayrDUmHe"
      },
      "source": [
        "## Generating Extractive Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P498sheF70LN"
      },
      "source": [
        "#To add a [CLS][SEP] between all consecutive lines in a document."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-Ye0w4difuF"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/nlpyang/PreSumm-dev/raw_input/input5_abs_navigation_amazon_kindle.txt.data\") as f1:\n",
        "    with open(\"/content/drive/MyDrive/nlpyang/PreSumm-dev/raw_input/input5_ext.txt\",'w') as f2:\n",
        "      for line in f1:\n",
        "        lines = line.split('.')[0]\n",
        "        f2.write(\" \" + \"[CLS]\" + \" \" + \"[SEP]\" + \" \" + lines + \".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVGTq1_ne9oY",
        "outputId": "077440cb-7a9d-4014-a469-1df6a56516f8"
      },
      "source": [
        "cd  /content/drive/MyDrive/nlpyang/PreSumm-dev/src"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1veaxwqyZvvFioYNDI_lezmN1zGiPBSEh/nlpyang/PreSumm-dev/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls6_vqQhxlGZ",
        "outputId": "0ef7c566-69e8-4060-d502-08e96dd28d5c"
      },
      "source": [
        "!python /content/drive/MyDrive/nlpyang/PreSumm-dev/src/train.py -task ext -mode test_text -text_src /content/drive/MyDrive/nlpyang/PreSumm-dev/raw_input/input5_ext.txt -result_path /content/drive/MyDrive/nlpyang/PreSumm-dev/raw_data/Extractive_5/output5_ext.txt -test_from /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_10000.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-04-09 13:47:51,307 INFO] Loading checkpoint from /content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_10000.pt\n",
            "Namespace(accum_count=1, alpha=0.6, batch_size=140, beam_size=5, bert_data_path='../bert_data_new/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/cnndm.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=150, max_ndocs_in_batch=6, max_pos=512, max_tgt_len=140, min_length=15, mode='test_text', model_path='../models/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='/content/drive/MyDrive/nlpyang/PreSumm-dev/raw_data/Extractive_5/output5_ext.txt', save_checkpoint_steps=5, seed=666, sep_optim=False, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=200, test_from='/content/drive/MyDrive/nlpyang/PreSumm-master/MODEL_PATH/model_step_10000.pt', test_start_from=-1, text_src='/content/drive/MyDrive/nlpyang/PreSumm-dev/raw_input/input5_ext.txt', text_tgt='', train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-04-09 13:47:54,058 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "[2021-04-09 13:47:54,059 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[2021-04-09 13:47:54,425 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "cpu\n",
            "----------------\n",
            "gpu_rank 0\n",
            "[2021-04-09 13:47:58,172 INFO] * number of parameters: 120512513\n",
            "[2021-04-09 13:47:58,564 INFO] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "100% 1/1 [00:02<00:00,  2.08s/it]\n",
            "[2021-04-09 13:48:00,690 INFO] Validation xent: 0 at step -1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAk_huOE7u_k"
      },
      "source": [
        "Output Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xrbNMsahZKl"
      },
      "source": [
        "\"\"\"\n",
        "INPUT 1  (PreSumm-dev --> raw_input --> input1_ext.txt)\n",
        "this Terry Jones had a love of the absurd that contributed much to the anarchic humour of Monty Python's Flying Circus. His style of visual comedy, leavened with a touch of the surreal, inspired many comedians who followed him. It was on Python that he honed his directing skills, notably on Life of Brian and The Meaning of Life. A keen historian, he wrote a number of books and fronted TV documentaries on ancient and medieval history. Terence Graham Parry Jones was born in Colwyn Bay in north Wales on 1 February 1942. His grandparents ran the local amateur operatic society and staged Gilbert and Sullivan concerts on the town's pier each year His family moved to Surrey when he was four but he always felt nostalgic about his native land. \"I couldn't bear it and for the longest time I wanted Wales back,\" he once said. \"I still feel very Welsh and feel it's where I should be really.\" After leaving the Royal Grammar School in Guildford, where he captained the school, he went on to read English at St Edmund Hall, Oxford. However, as he put it, he \"strayed into history\", the subject in which he graduated. While at Oxford he wrote sketches for the Oxford Revue and performed alongside a fellow student, Michael Palin.\n",
        "(CNN) An Iranian chess referee says she is frightened to return home after she was criticized online for not wearing the appropriate headscarf during an international tournament. Currently the chief adjudicator at the Women's World Chess Championship held in Russia and China, Shohreh Bayat says she fears arrest after a photograph of her was taken during the event and was then circulated online in Iran. \"They are very sensitive about the hijab when we are representing Iran in international events and even sometimes they send a person with the team to control our hijab,\" Bayat told CNN Sport in a phone interview Tuesday. The headscarf, or the hijab, has been a mandatory part of women's dress in Iran since the 1979 Islamic revolution but, in recent years, some women have mounted opposition and staged protests about headwear rules. Bayat said she had been wearing a headscarf at the tournament but that certain camera angles had made it look like she was not. \"If I come back to Iran, I think there are a few possibilities. It is highly possible that they arrest me [...] or it is possible that they invalidate my passport,\" added Bayat. \"I think they want to make an example of me.\" The photographs were taken at the first stage of the chess championship in Shanghai, China, but Bayat has since flown to Vladivostok, Russia, for the second leg between Ju Wenjun and Aleksandra Goryachkina. She was left \"panicked and shocked\" when she became aware of the reaction in Iran after checking her phone in the hotel room. The 32-year-old said she felt helpless as websites reportedly condemned her for what some described as protesting the country's compulsory law. Subsequently, Bayat has decided to no longer wear the headscarf. \"I'm not wearing it anymore because what is the point? I was just tolerating it, I don't believe in the hijab,\" she added. \"People must be free to choose to wear what they want, and I was only wearing the hijab because I live in Iran and I had to wear it. I had no other choice.\" Bayat says she sought help from the country's chess federation. She says the federation told her to post an apology on her social media channels. She agreed under the condition that the federation would guarantee her safety but she said they refused. \"My husband is in Iran, my parents are in Iran, all my family members are in Iran. I don't have anyone else outside of Iran. I don't know what to say, this is a very hard situation,\" she said. CNN contacted the Iranian Chess Federation on Tuesday but has yet to receive a response.\n",
        "\n",
        "OUTPUT 1 (Abstractively summarized) (Presumm-dev --> raw_data --> Extractive_1 --> output1_ext.txt_step-1.candidate )\n",
        "this Terry Jones had a love of the absurd that contributed much to the anarchic humour of Monty Python's Flying Circus.\n",
        "An Iranian chess referee says she is frightened to return home after she was criticized online for not wearing the appropriate headscarf during an international tournament.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syYFIEoR_HKP"
      },
      "source": [
        "## TASK 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q615EPC_Nvn"
      },
      "source": [
        "Use a custom summarization dataset of your choice, train the model on this data and report your findings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK7-Qvkn_LuP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}