{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rouge_Score_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvqBgwl5STWc"
      },
      "source": [
        "#Dependencies: \n",
        "\n",
        "#tensorboardX\n",
        "#torch==1.1.0\n",
        "#pytorch_transformers\n",
        "#multiprocess==0.70.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIiA-lTTh0kx"
      },
      "source": [
        "!git clone https://github.com/andersjo/pyrouge.git rouge\n",
        "!git clone https://github.com/bheinzerling/pyrouge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruvfngvKiVpJ"
      },
      "source": [
        "cd pyrouge/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdC77rYFiand"
      },
      "source": [
        "!python setup.py install\n",
        "!pyrouge_set_rouge_path '/content/rouge/tools/ROUGE-1.5.5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7e8MGUiif49"
      },
      "source": [
        "cd ../rouge/tools/ROUGE-1.5.5/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRPTnLHIikMO"
      },
      "source": [
        "!rm \"WordNet-2.0.exc.db\"\n",
        "!perl ./WordNet-2.0-Exceptions/buildExeptionDB.pl ./WordNet-2.0-Exceptions ./smart_common_words.txt ./WordNet-2.0.exc.db\n",
        "!cpan install XML::DOM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmmlEJfKiqPZ"
      },
      "source": [
        "!python -m pyrouge.test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEgD-0aqgFJR"
      },
      "source": [
        "ROUGE SCORE CALCULATION FOR MODEL TRAINED CUSTOM DATASET (BBC NEWS SUMMARIES)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_VsSuhTJ1aO"
      },
      "source": [
        "!python /content/drive/MyDrive/nlpyang/PreSumm-master/src/train.py -task ext -mode test -batch_size 3000 -test_batch_size 50 -bert_data_path /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/_test/cnndm -log_file /content/drive/MyDrive/nlpyang/PreSumm-master/logs/eval_custom -model_path /content/drive/MyDrive/nlpyang/PreSumm-master/CUSTOM_MODEL -test_from /content/drive/MyDrive/nlpyang/PreSumm-master/CUSTOM_MODEL/model_step_10000.pt -sep_optim true -use_interval true -visible_gpus 0 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path /content/drive/MyDrive/nlpyang/PreSumm-master/rouge/result \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhxJYpxz03uR"
      },
      "source": [
        "ROUGE SCORE CALCULATION FOR BERTEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BhNMUYb3-bm"
      },
      "source": [
        "!python /content/drive/MyDrive/nlpyang/PreSumm-master/src/train.py -task ext -mode test -batch_size 3000 -test_batch_size 50 -bert_data_path /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/_test/cnndm -log_file /content/drive/MyDrive/nlpyang/PreSumm-master/logs/eval_BertExt -model_path /content/drive/MyDrive/nlpyang/Model_Checkpoints/BertExt -test_from /content/drive/MyDrive/nlpyang/Model_Checkpoints/BertExt/model_step_50000.pt -sep_optim true -use_interval true -visible_gpus 0 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path /content/drive/MyDrive/nlpyang/PreSumm-master/rouge/result_BertExt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcR_gqHN4ipk"
      },
      "source": [
        "ROUGE SCORE CALCULATION FOR BERTEXTABS (Approx. 5 hours to compute)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFFRdrFc4iKi"
      },
      "source": [
        "!python /content/drive/MyDrive/nlpyang/PreSumm-master/src/train.py -task abs -mode test -batch_size 3000 -test_batch_size 50 -bert_data_path /content/drive/MyDrive/nlpyang/PreSumm-master/bert_data/_test/cnndm -log_file /content/drive/MyDrive/nlpyang/PreSumm-master/logs/eval_BertExtABS -model_path /content/drive/MyDrive/nlpyang/Model_Checkpoints/BertExtAbs -test_from /content/drive/MyDrive/nlpyang/Model_Checkpoints/BertExtAbs/model_step_8000.pt -sep_optim true -use_interval true -visible_gpus 0 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path /content/drive/MyDrive/nlpyang/PreSumm-master/rouge/result_BertExtAbs\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}